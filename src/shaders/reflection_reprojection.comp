#version 450

#extension GL_GOOGLE_include_directive : require

#include "common.glsl"

// ------------------------------------------------------------------
// DEFINES ----------------------------------------------------------
// ------------------------------------------------------------------

#define NUM_THREADS 32
#define GLOSSY_ROUGHNESS_THRESHOLD 0.05f
#define EPSILON 0.0001f

// ------------------------------------------------------------------
// INPUTS -----------------------------------------------------------
// ------------------------------------------------------------------

layout(local_size_x = NUM_THREADS, local_size_y = NUM_THREADS, local_size_z = 1) in;

// ------------------------------------------------------------------
// DESCRIPTOR SETS --------------------------------------------------
// ------------------------------------------------------------------

layout(set = 0, binding = 0, rgba16f) uniform image2D i_ReprojectedColor;

layout(set = 1, binding = 0) uniform sampler2D s_Color;
layout(set = 2, binding = 0) uniform sampler2D s_PrevColor;

layout(set = 3, binding = 0) uniform sampler2D s_GBuffer1; // RGB: Albedo, A: Roughness
layout(set = 3, binding = 1) uniform sampler2D s_GBuffer2; // RGB: Normal, A: Metallic
layout(set = 3, binding = 2) uniform sampler2D s_GBuffer3; // RG: Motion Vector, BA: -
layout(set = 3, binding = 3) uniform sampler2D s_GBufferDepth;

layout(set = 4, binding = 0) uniform PerFrameUBO
{
    mat4  view_inverse;
    mat4  proj_inverse;
    mat4  view_proj_inverse;
    mat4  prev_view_proj;
    mat4  view_proj;
    vec4  cam_pos;
    Light light;
}
ubo;

// ------------------------------------------------------------------------
// PUSH CONSTANTS ---------------------------------------------------------
// ------------------------------------------------------------------------

layout(push_constant) uniform PushConstants
{
    uint  first_frame;
    uint  neighborhood_clamping;
    float neighborhood_std_scale;
    float alpha;
    int  g_buffer_mip;
}
u_PushConstants;

// ------------------------------------------------------------------
// FUNCTIONS --------------------------------------------------------
// ------------------------------------------------------------------

float luminance(vec3 color)
{
    return max(dot(color, vec3(0.299, 0.587, 0.114)), 0.0001);
}

// ------------------------------------------------------------------

vec3 clip_aabb(vec3 aabb_min, vec3 aabb_max, vec3 history_sample)
{
    // Note: only clips towards aabb center
    vec3 aabb_center = 0.5f * (aabb_max + aabb_min);
    vec3 extent_clip = 0.5f * (aabb_max - aabb_min) + 0.001f;

    // Find color vector
    vec3 color_vector = history_sample - aabb_center;
    // Transform into clip space
    vec3 color_vector_clip = color_vector / extent_clip;
    // Find max absolute component
    color_vector_clip  = abs(color_vector_clip);
    float max_abs_unit = max(max(color_vector_clip.x, color_vector_clip.y), color_vector_clip.z);

    if (max_abs_unit > 1.0)
        return aabb_center + color_vector / max_abs_unit; // clip towards color vector
    else
        return history_sample; // point is inside aabb
}

// ------------------------------------------------------------------

vec3 neighborhood_standard_deviation(ivec2 coord)
{
    vec3 color_sum         = vec3(0.0f);
    vec3 color_sum_squared = vec3(0.0f);

    int   radius = 1;
    float weight = (float(radius) * 2.0f + 1.0f) * (float(radius) * 2.0f + 1.0f);

    for (int dx = -radius; dx <= radius; dx++)
    {
        for (int dy = -radius; dy <= radius; dy++)
        {
            ivec2 sample_coord = coord + ivec2(dx, dy);
            vec3  sample_color = texelFetch(s_Color, sample_coord, 0).rgb;

            color_sum += sample_color;
            color_sum_squared += sample_color * sample_color;
        }
    }

    vec3 color_std = (color_sum_squared - color_sum * color_sum / weight) / (weight - 1.0f);
    return sqrt(max(color_std, 0.0f));
}

// ------------------------------------------------------------------

ivec2 surface_point_reprojection(ivec2 coord, vec2 motion_vector, ivec2 size)
{
    return coord + ivec2(motion_vector * vec2(size));
}

// ------------------------------------------------------------------

ivec2 hit_point_reprojection(vec3 ray_origin, float ray_length, ivec2 size)
{
    vec3 camera_ray = ray_origin - ubo.cam_pos.xyz;

    float camera_ray_length     = length(camera_ray);
    float reflection_ray_length = ray_length;

    camera_ray = normalize(camera_ray);

    vec3 parallax_hit_point = ubo.cam_pos.xyz + camera_ray * (camera_ray_length + reflection_ray_length);

    vec4 reprojected_parallax_hit_point = ubo.prev_view_proj * vec4(parallax_hit_point, 1.0f);

    reprojected_parallax_hit_point.xy /= reprojected_parallax_hit_point.w;

    return ivec2((reprojected_parallax_hit_point.xy * 0.5f + 0.5f) * vec2(size));
}

// ------------------------------------------------------------------

vec3 world_position_from_depth(vec2 tex_coords, float ndc_depth)
{
    // Take texture coordinate and remap to [-1.0, 1.0] range.
    vec2 screen_pos = tex_coords * 2.0 - 1.0;

    // // Create NDC position.
    vec4 ndc_pos = vec4(screen_pos, ndc_depth, 1.0);

    // Transform back into world position.
    vec4 world_pos = ubo.view_proj_inverse * ndc_pos;

    // Undo projection.
    world_pos = world_pos / world_pos.w;

    return world_pos.xyz;
}

// ------------------------------------------------------------------------

float normal_edge_stopping_weight(vec3 a, vec3 b)
{
    return pow(max(dot(a, b), 0.0f), 32);
}

// ------------------------------------------------------------------------

float depth_edge_stopping_weight(float center_lin_depth, float sample_lin_depth)
{
    return clamp(1.0f - abs(center_lin_depth - sample_lin_depth), 0.0f, 1.0f);
}

// ------------------------------------------------------------------

vec3 sample_history(ivec2 current_coord, ivec2 history_coord, vec3 aabb_min, vec3 aabb_max)
{
    vec3 history_color = texelFetch(s_PrevColor, history_coord, 0).rgb;

    if (u_PushConstants.neighborhood_clamping == 1)
        history_color = clamp(history_color.xyz, aabb_min, aabb_max);
    //history_color = clip_aabb(aabb_min, aabb_max, history_color.xyz).xyz;

    vec3 current_normal = texelFetch(s_GBuffer2, current_coord, 0).rgb;
    vec3 history_normal = texelFetch(s_GBuffer2, history_coord, 0).rgb;

    return history_color;
}

// ------------------------------------------------------------------

float compute_temporal_variance(float current_sample_luma, float history_sample_luma)
{
    return abs(current_sample_luma - history_sample_luma) / max(max(current_sample_luma, history_sample_luma), EPSILON);
}

// ------------------------------------------------------------------
// MAIN -------------------------------------------------------------
// ------------------------------------------------------------------

void main()
{
    // Query the G-Buffer image size
    ivec2 size = textureSize(s_GBuffer1, 0);

    // Compute current pixel coord
    ivec2 current_coord = ivec2(gl_GlobalInvocationID.xy);

    // Sample center depth and reject if sample belongs to the background
    float center_depth = texelFetch(s_GBufferDepth, current_coord, 0).r;

    if (center_depth == 1.0f)
    {
        imageStore(i_ReprojectedColor, current_coord, vec4(0.0f));
        return;
    }

    // Compute the texture coord
    vec2 tex_coord = (vec2(current_coord) + vec2(0.5f)) / vec2(size);

    // Compute world position for the current pixel
    vec3 world_pos = world_position_from_depth(tex_coord, textureLod(s_GBufferDepth, tex_coord, 0.0f).r);

    // Sample the ray length for the current pixel
    float ray_length = 0.0f; // texelFetch(s_Hit, current_coord, 0).a;

    // Sample the motion vector for the current pixel
    vec4 motion = texelFetch(s_GBuffer3, current_coord, 0);

    // Sample the roughness for the current pixel
    float roughness = texelFetch(s_GBuffer1, current_coord, 0).a;

    // Compute the reprojected surface point coord
    ivec2 surface_point_coord = surface_point_reprojection(current_coord, motion.xy, size);

    // Compute the reprojected hit point coord
    ivec2 hit_point_coord = hit_point_reprojection(world_pos, ray_length, size);

    // If the pixel roughness is below the glossy roughness threshold, use the reprojected hit point coord,
    // otherwise you the reprojected surface point coord.
    ivec2 reprojected_coord = (roughness < GLOSSY_ROUGHNESS_THRESHOLD && ray_length > 0.0f) ? hit_point_coord : surface_point_coord;

    // Fetch current and previous pixels
    vec3 current_sample = texelFetch(s_Color, current_coord, 0).rgb;

    // Initialize outputs
    vec3  blended_sample    = current_sample;
    float temporal_variance = 0.0f;

    if (any(greaterThanEqual(current_coord, ivec2(0, 0))) && any(lessThan(current_coord, size)))
    {
        vec3 color_std = neighborhood_standard_deviation(current_coord);
        color_std *= u_PushConstants.neighborhood_std_scale;

        vec3 radiance_min = current_sample.xyz - color_std;
        vec3 radiance_max = current_sample.xyz + color_std;

        vec3 history_sample = sample_history(current_coord, reprojected_coord, radiance_min, radiance_max);
        temporal_variance   = compute_temporal_variance(luminance(current_sample), luminance(history_sample));

        // Blend previous and current sample
        float feedback = (1.0f - u_PushConstants.alpha);
        blended_sample = mix(current_sample, history_sample, feedback);
    }

    // Store blended sample into the storage image
    imageStore(i_ReprojectedColor, current_coord, vec4(blended_sample, temporal_variance));
}

// ------------------------------------------------------------------