#version 450

#extension GL_GOOGLE_include_directive : require

#include "common.glsl"

// ------------------------------------------------------------------
// DEFINES ----------------------------------------------------------
// ------------------------------------------------------------------

#define NUM_THREADS 32

// ------------------------------------------------------------------
// INPUTS -----------------------------------------------------------
// ------------------------------------------------------------------

layout(local_size_x = NUM_THREADS, local_size_y = NUM_THREADS, local_size_z = 1) in;

// ------------------------------------------------------------------
// DESCRIPTOR SETS --------------------------------------------------
// ------------------------------------------------------------------

layout(set = 0, binding = 0, rgba16f) uniform image2D i_Color;
layout(set = 1, binding = 0, r16f) uniform image2D i_HistoryLength;

// Current G-buffer DS
layout(set = 2, binding = 0) uniform sampler2D s_Roughness;
layout(set = 2, binding = 2) uniform sampler2D s_MotionVectors;
layout(set = 2, binding = 3) uniform sampler2D s_Depth;
layout(set = 2, binding = 4) uniform sampler2D s_LinearZ;

// Previous G-Buffer DS
layout(set = 3, binding = 4) uniform sampler2D s_PrevLinearZ;

// Current SVGF Read DS
layout(set = 4, binding = 0) uniform sampler2D s_Color;
layout(set = 5, binding = 0) uniform sampler2D s_PrevColor;

layout(set = 6, binding = 0) uniform PerFrameUBO
{
    mat4  view_inverse;
    mat4  proj_inverse;
    mat4  view_proj_inverse;
    mat4  prev_view_proj;
    mat4  view_proj;
    vec4  cam_pos;
    Light light;
}
ubo;

// ------------------------------------------------------------------
// PUSH CONSTANTS ---------------------------------------------------
// ------------------------------------------------------------------

layout(push_constant) uniform PushConstants
{
    float alpha;
}
u_PushConstants;

// ------------------------------------------------------------------
// FUNCTIONS --------------------------------------------------------
// ------------------------------------------------------------------

bool is_reprojection_valid(ivec2 coord, float Z, float Zprev, float fwidthZ, vec3 normal, vec3 normalPrev, float fwidthNormal)
{
    const ivec2 imageDim = textureSize(s_PrevColor, 0);
    // check whether reprojected pixel is inside of the screen
    if (any(lessThan(coord, ivec2(1, 1))) || any(greaterThan(coord, imageDim - ivec2(1, 1)))) return false;
    // check if deviation of depths is acceptable
    if (abs(Zprev - Z) / (fwidthZ + 1e-4) > 2.0) return false;
    // check normals for compatibility
    if (distance(normal, normalPrev) / (fwidthNormal + 1e-2) > 16.0) return false;

    return true;
}

// ------------------------------------------------------------------

vec3 world_position_from_depth(vec2 tex_coords, float ndc_depth)
{
    // Take texture coordinate and remap to [-1.0, 1.0] range.
    vec2 screen_pos = tex_coords * 2.0 - 1.0;

    // // Create NDC position.
    vec4 ndc_pos = vec4(screen_pos, ndc_depth, 1.0);

    // Transform back into world position.
    vec4 world_pos = ubo.view_proj_inverse * ndc_pos;

    // Undo projection.
    world_pos = world_pos / world_pos.w;

    return world_pos.xyz;
}

// ------------------------------------------------------------------

vec3 octohedral_to_direction(uint octo)
{
    vec2 e = unpackSnorm2x16(octo);
    vec3 v = vec3(e, 1.0 - abs(e.x) - abs(e.y));
    if (v.z < 0.0)
        v.xy = (1.0 - abs(v.yx)) * (step(0.0, v.xy) * 2.0 - vec2(1.0));
    return normalize(v);
}

// ------------------------------------------------------------------

float luminance(vec3 rgb)
{
    return dot(rgb, vec3(0.2126f, 0.7152f, 0.0722f));
}

// ------------------------------------------------------------------

vec2 surface_point_reprojection(ivec2 coord, vec2 motion_vector, ivec2 size)
{
    return vec2(coord) + (motion_vector * vec2(size));
}

// ------------------------------------------------------------------

bool load_prev_data(ivec2 fragCoord, vec2 posPrev, vec4 motion, out vec4 prevColor, out float historyLength)
{
    const ivec2 ipos     = fragCoord;
    const vec2  imageDim = vec2(textureSize(s_PrevColor, 0));

    // stores: linearZ, maxChangeZ, prevLinearZ, objNorm
    vec4 depth  = texelFetch(s_LinearZ, ipos, 0);
    vec3 normal = octohedral_to_direction(floatBitsToUint(depth.w));

    const ivec2 iposPrev = ivec2(vec2(posPrev) + vec2(0.5f));
    prevColor = vec4(0, 0, 0, 0);

    bool       v[4];
    ivec2      offset[4] = { ivec2(0, 0), ivec2(1, 0), ivec2(0, 1), ivec2(1, 1) };

    // check for all 4 taps of the bilinear filter for validity
    bool valid = false;
    for (int sampleIdx = 0; sampleIdx < 4; sampleIdx++)
    {
        ivec2 loc        = ivec2(posPrev) + offset[sampleIdx];
        vec4  depthPrev  = texelFetch(s_PrevLinearZ, loc, 0);
        vec3  normalPrev = octohedral_to_direction(floatBitsToUint(depthPrev.w));

        v[sampleIdx] = is_reprojection_valid(iposPrev, depth.z, depthPrev.x, depth.y, normal, normalPrev, motion.w);

        valid = valid || v[sampleIdx];
    }

    if (valid)
    {
        float sumw = 0;
        float x    = fract(posPrev.x);
        float y    = fract(posPrev.y);

        // bilinear weights
        float w[4] = { (1 - x) * (1 - y),
                       x * (1 - y),
                       (1 - x) * y,
                       x * y };

        prevColor   = vec4(0, 0, 0, 0);

        // perform the actual bilinear interpolation
        for (int sampleIdx = 0; sampleIdx < 4; sampleIdx++)
        {
            ivec2 loc = ivec2(posPrev) + offset[sampleIdx];

            if (v[sampleIdx])
            {
                prevColor += w[sampleIdx] * texelFetch(s_PrevColor, loc, 0);
                sumw += w[sampleIdx];
            }
        }

        // redistribute weights in case not all taps were used
        valid       = (sumw >= 0.01);
        prevColor   = valid ? prevColor / sumw : vec4(0, 0, 0, 0);
    }
    if (!valid) // perform cross-bilateral filter in the hope to find some suitable samples somewhere
    {
        float cnt = 0.0;

        // this code performs a binary descision for each tap of the cross-bilateral filter
        const int radius = 1;
        for (int yy = -radius; yy <= radius; yy++)
        {
            for (int xx = -radius; xx <= radius; xx++)
            {
                ivec2 p            = iposPrev + ivec2(xx, yy);
                vec4  depthFilter  = texelFetch(s_PrevLinearZ, p, 0);
                vec3  normalFilter = octohedral_to_direction(floatBitsToUint(depthFilter.w));

                if (is_reprojection_valid(iposPrev, depth.z, depthFilter.x, depth.y, normal, normalFilter, motion.w))
                {
                    prevColor += texelFetch(s_PrevColor, p, 0);
                    cnt += 1.0;
                }
            }
        }
        if (cnt > 0)
        {
            valid = true;
            prevColor /= cnt;
        }
    }

    if (valid)
    {
        // crude, fixme
        historyLength = imageLoad(i_HistoryLength, iposPrev).r;
    }
    else
    {
        prevColor     = vec4(0, 0, 0, 0);
        historyLength = 0;
    }

    return valid;
}

// ------------------------------------------------------------------
// MAIN -------------------------------------------------------------
// ------------------------------------------------------------------

void main()
{
    // Query the image size
    ivec2 size = textureSize(s_Color, 0);

    // Compute current pixel coord
    ivec2 current_coord = ivec2(gl_GlobalInvocationID.xy);

    // Sample center depth and reject if sample belongs to the background
    float center_depth = texelFetch(s_Depth, current_coord, 0).r;

    if (center_depth == 1.0f)
    {
        imageStore(i_Color, current_coord, vec4(0.0f));
        imageStore(i_HistoryLength, current_coord, vec4(0.0f));
        return;
    }
    
    // Compute the texture coord
    vec2 tex_coord = (vec2(current_coord) + vec2(0.5f)) / vec2(size);

    // Compute world position for the current pixel
    vec3 world_pos = world_position_from_depth(tex_coord, textureLod(s_Depth, tex_coord, 0.0f).r);

    // Sample the ray length for the current pixel
    vec4 current = texelFetch(s_Color, current_coord, 0);
    vec3 color = current.xyz;
    float ray_length = current.w;

    // Sample the motion vector for the current pixel
    vec4 motion = texelFetch(s_MotionVectors, current_coord, 0);

    // Compute the reprojected surface point coord
    vec2 reprojected_coord = surface_point_reprojection(current_coord, motion.xy, size);
    
    float history_length;
    vec4  prev_color;
    bool  success  = load_prev_data(current_coord, reprojected_coord, motion, prev_color, history_length);
    history_length = min(32.0f, success ? history_length + 1.0f : 1.0f);

    // this adjusts the alpha for the case where insufficient history is available.
    // It boosts the temporal accumulation to give the samples equal weights in
    // the beginning.
    const float alpha = success ? max(u_PushConstants.alpha, 1.0 / history_length) : 1.0;

    vec4 out_color = mix(prev_color, vec4(color, 0.0f), alpha);
    
    // temporal integration
    imageStore(i_Color, current_coord, out_color);
    imageStore(i_HistoryLength, current_coord, vec4(history_length));
}

// ------------------------------------------------------------------