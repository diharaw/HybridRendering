#version 450

#extension GL_GOOGLE_include_directive : require

#include "common.glsl"

// ------------------------------------------------------------------
// DEFINES ----------------------------------------------------------
// ------------------------------------------------------------------

#define NUM_THREADS 32
#define GLOSSY_ROUGHNESS_THRESHOLD 0.05f

// ------------------------------------------------------------------
// INPUTS -----------------------------------------------------------
// ------------------------------------------------------------------

layout(local_size_x = NUM_THREADS, local_size_y = NUM_THREADS, local_size_z = 1) in;

// ------------------------------------------------------------------
// DESCRIPTOR SETS --------------------------------------------------
// ------------------------------------------------------------------

layout(set = 0, binding = 0, rgba16f) uniform image2D i_Color;
layout(set = 1, binding = 0, r16f) uniform image2D i_HistoryLength;

// Current G-buffer DS
layout(set = 2, binding = 0) uniform sampler2D s_Roughness;
layout(set = 2, binding = 2) uniform sampler2D s_MotionVectors;
layout(set = 2, binding = 3) uniform sampler2D s_Depth;
layout(set = 2, binding = 4) uniform sampler2D s_LinearZ;

// Previous G-Buffer DS
layout(set = 3, binding = 4) uniform sampler2D s_PrevLinearZ;

// Current SVGF Read DS
layout(set = 4, binding = 0) uniform sampler2D s_Color;
layout(set = 5, binding = 0) uniform sampler2D s_PrevColor;

layout(set = 6, binding = 0) uniform PerFrameUBO
{
    mat4  view_inverse;
    mat4  proj_inverse;
    mat4  view_proj_inverse;
    mat4  prev_view_proj;
    mat4  view_proj;
    vec4  cam_pos;
    Light light;
}
ubo;

// ------------------------------------------------------------------
// PUSH CONSTANTS ---------------------------------------------------
// ------------------------------------------------------------------

layout(push_constant) uniform PushConstants
{
    float alpha;
    int  g_buffer_mip;
}
u_PushConstants;

// ------------------------------------------------------------------
// CONSTANTS  -------------------------------------------------------
// ------------------------------------------------------------------

const float FLT_EPS = 0.00000001;

// ------------------------------------------------------------------
// FUNCTIONS --------------------------------------------------------
// ------------------------------------------------------------------

float max_3(float x, float y, float z) { return max(x, max(y, z)); }

// ------------------------------------------------------------------

// Apply this to tonemap linear HDR color "c" after a sample is fetched in the resolve.
// Note "c" 1.0 maps to the expected limit of low-dynamic-range monitor output.
vec3 tonemap(vec3 c) { return c / (max_3(c.r, c.g, c.b) + 1.0f); }

// ------------------------------------------------------------------

// Apply this to restore the linear HDR color before writing out the result of the resolve.
vec3 tonemap_invert(vec3 c) { return c / (1.0f - max_3(c.r, c.g, c.b)); }

// ------------------------------------------------------------------

bool is_reprojection_valid(ivec2 coord, float Z, float Zprev, float fwidthZ, vec3 normal, vec3 normalPrev, float fwidthNormal)
{
    const ivec2 imageDim = textureSize(s_PrevColor, 0);
    // check whether reprojected pixel is inside of the screen
    if (any(lessThan(coord, ivec2(1, 1))) || any(greaterThan(coord, imageDim - ivec2(1, 1)))) return false;
    // check if deviation of depths is acceptable
    if (abs(Zprev - Z) / (fwidthZ + 1e-4) > 2.0) return false;
    // check normals for compatibility
    if (distance(normal, normalPrev) / (fwidthNormal + 1e-2) > 16.0) return false;

    return true;
}

// ------------------------------------------------------------------

vec3 clip_aabb(vec3 aabb_min, vec3 aabb_max, vec3 history_sample)
{
    // Note: only clips towards aabb center
    vec3 aabb_center = 0.5f * (aabb_max + aabb_min);
    vec3 extent_clip = 0.5f * (aabb_max - aabb_min) + 0.001f;

    // Find color vector
    vec3 color_vector = history_sample - aabb_center;
    // Transform into clip space
    vec3 color_vector_clip = color_vector / extent_clip;
    // Find max absolute component
    color_vector_clip  = abs(color_vector_clip);
    float max_abs_unit = max(max(color_vector_clip.x, color_vector_clip.y), color_vector_clip.z);

    if (max_abs_unit > 1.0)
        return aabb_center + color_vector / max_abs_unit; // clip towards color vector
    else
        return history_sample; // point is inside aabb
}

// ------------------------------------------------------------------

vec3 neighborhood_standard_deviation(ivec2 coord)
{
    vec3 m1 = vec3(0.0f);
    vec3 m2 = vec3(0.0f);

    int   radius = 1;
    float N      = (float(radius) * 2.0f + 1.0f) * (float(radius) * 2.0f + 1.0f);

    for (int dx = -radius; dx <= radius; dx++)
    {
        for (int dy = -radius; dy <= radius; dy++)
        {
            ivec2 sample_coord = coord + ivec2(dx, dy);
            vec3  sample_color = tonemap(texelFetch(s_Color, sample_coord, 0).rgb);

            m1 += sample_color;
            m2 += sample_color * sample_color;
        }
    }

    vec3 mu    = m1 / N;
    vec3 sigma = sqrt(m2 / N - mu * mu);

    return sigma;
}

// ------------------------------------------------------------------

void neighborhood_min_max(ivec2 coord, vec3 aabb_min, vec3 aabb_max)
{
    int radius = 1;

    for (int dx = -radius; dx <= radius; dx++)
    {
        for (int dy = -radius; dy <= radius; dy++)
        {
            ivec2 sample_coord = coord + ivec2(dx, dy);
            vec3  sample_color = texelFetch(s_Color, sample_coord, 0).rgb;

            aabb_min = min(aabb_min, sample_color);
            aabb_max = max(aabb_max, sample_color);
        }
    }
}

// ------------------------------------------------------------------

vec3 world_position_from_depth(vec2 tex_coords, float ndc_depth)
{
    // Take texture coordinate and remap to [-1.0, 1.0] range.
    vec2 screen_pos = tex_coords * 2.0 - 1.0;

    // // Create NDC position.
    vec4 ndc_pos = vec4(screen_pos, ndc_depth, 1.0);

    // Transform back into world position.
    vec4 world_pos = ubo.view_proj_inverse * ndc_pos;

    // Undo projection.
    world_pos = world_pos / world_pos.w;

    return world_pos.xyz;
}

// ------------------------------------------------------------------

vec3 octohedral_to_direction(uint octo)
{
    vec2 e = unpackSnorm2x16(octo);
    vec3 v = vec3(e, 1.0 - abs(e.x) - abs(e.y));
    if (v.z < 0.0)
        v.xy = (1.0 - abs(v.yx)) * (step(0.0, v.xy) * 2.0 - vec2(1.0));
    return normalize(v);
}

// ------------------------------------------------------------------

float luminance(vec3 rgb)
{
    return dot(rgb, vec3(0.2126f, 0.7152f, 0.0722f));
}

// ------------------------------------------------------------------

vec2 surface_point_reprojection(ivec2 coord, vec2 motion_vector, ivec2 size)
{
    return vec2(coord) + (motion_vector * vec2(size));
}

// ------------------------------------------------------------------

vec2 hit_point_reprojection(vec3 ray_origin, float ray_length, ivec2 size)
{
    vec3 camera_ray = ray_origin - ubo.cam_pos.xyz;

    float camera_ray_length     = length(camera_ray);
    float reflection_ray_length = ray_length;

    camera_ray = normalize(camera_ray);

    vec3 parallax_hit_point = ubo.cam_pos.xyz + camera_ray * (camera_ray_length + reflection_ray_length);

    vec4 reprojected_parallax_hit_point = ubo.prev_view_proj * vec4(parallax_hit_point, 1.0f);

    reprojected_parallax_hit_point.xy /= reprojected_parallax_hit_point.w;

    return (reprojected_parallax_hit_point.xy * 0.5f + 0.5f) * vec2(size);
}

// ------------------------------------------------------------------

bool load_prev_data(ivec2 fragCoord, vec2 posPrev, vec4 motion, out vec4 prevColor, out float historyLength)
{
    const ivec2 ipos     = fragCoord;
    const vec2  imageDim = vec2(textureSize(s_PrevColor, 0));

    // stores: linearZ, maxChangeZ, prevLinearZ, objNorm
    vec4 depth  = texelFetch(s_LinearZ, ipos, 0);
    vec3 normal = octohedral_to_direction(floatBitsToUint(depth.w));

    const ivec2 iposPrev = ivec2(vec2(posPrev) + vec2(0.5f));
    prevColor            = vec4(0, 0, 0, 0);

    bool  v[4];
    ivec2 offset[4] = { ivec2(0, 0), ivec2(1, 0), ivec2(0, 1), ivec2(1, 1) };

    // check for all 4 taps of the bilinear filter for validity
    bool valid = false;
    for (int sampleIdx = 0; sampleIdx < 4; sampleIdx++)
    {
        ivec2 loc        = ivec2(posPrev) + offset[sampleIdx];
        vec4  depthPrev  = texelFetch(s_PrevLinearZ, loc, 0);
        vec3  normalPrev = octohedral_to_direction(floatBitsToUint(depthPrev.w));

        v[sampleIdx] = is_reprojection_valid(iposPrev, depth.z, depthPrev.x, depth.y, normal, normalPrev, motion.w);

        valid = valid || v[sampleIdx];
    }

    if (valid)
    {
        float sumw = 0;
        float x    = fract(posPrev.x);
        float y    = fract(posPrev.y);

        // bilinear weights
        float w[4] = { (1 - x) * (1 - y),
                       x * (1 - y),
                       (1 - x) * y,
                       x * y };

        prevColor = vec4(0, 0, 0, 0);

        // perform the actual bilinear interpolation
        for (int sampleIdx = 0; sampleIdx < 4; sampleIdx++)
        {
            ivec2 loc = ivec2(posPrev) + offset[sampleIdx];

            if (v[sampleIdx])
            {
                prevColor += w[sampleIdx] * texelFetch(s_PrevColor, loc, 0);
                sumw += w[sampleIdx];
            }
        }

        // redistribute weights in case not all taps were used
        valid     = (sumw >= 0.01);
        prevColor = valid ? prevColor / sumw : vec4(0, 0, 0, 0);
    }
    if (!valid) // perform cross-bilateral filter in the hope to find some suitable samples somewhere
    {
        float cnt = 0.0;

        // this code performs a binary descision for each tap of the cross-bilateral filter
        const int radius = 1;
        for (int yy = -radius; yy <= radius; yy++)
        {
            for (int xx = -radius; xx <= radius; xx++)
            {
                ivec2 p            = iposPrev + ivec2(xx, yy);
                vec4  depthFilter  = texelFetch(s_PrevLinearZ, p, 0);
                vec3  normalFilter = octohedral_to_direction(floatBitsToUint(depthFilter.w));

                if (is_reprojection_valid(iposPrev, depth.z, depthFilter.x, depth.y, normal, normalFilter, motion.w))
                {
                    prevColor += texelFetch(s_PrevColor, p, 0);
                    cnt += 1.0;
                }
            }
        }
        if (cnt > 0)
        {
            valid = true;
            prevColor /= cnt;
        }
    }

    if (valid)
    {
        // crude, fixme
        historyLength = imageLoad(i_HistoryLength, iposPrev).r;
    }
    else
    {
        prevColor     = vec4(0, 0, 0, 0);
        historyLength = 0;
    }

    return valid;
}

// ------------------------------------------------------------------
// MAIN -------------------------------------------------------------
// ------------------------------------------------------------------

void main()
{
    // Query the G-Buffer image size
    ivec2 size = textureSize(s_Color, 0);

    // Compute current pixel coord
    ivec2 current_coord = ivec2(gl_GlobalInvocationID.xy);

    // Sample center depth and reject if sample belongs to the background
    float center_depth = texelFetch(s_Depth, current_coord, 0).r;

    if (center_depth == 1.0f)
    {
        imageStore(i_Color, current_coord, vec4(0.0f));
        imageStore(i_HistoryLength, current_coord, vec4(0.0f));
        return;
    }

    // Compute the texture coord
    vec2 tex_coord = (vec2(current_coord) + vec2(0.5f)) / vec2(size);

    // Compute world position for the current pixel
    vec3 world_pos = world_position_from_depth(tex_coord, textureLod(s_Depth, tex_coord, 0.0f).r);

    // Sample the ray length for the current pixel
    vec4  current    = texelFetch(s_Color, current_coord, 0);
    vec3  color      = tonemap(current.xyz);
    float ray_length = current.w;

    float roughness = texelFetch(s_Roughness, current_coord, 0).a;

    // Sample the motion vector for the current pixel
    vec4 motion = texelFetch(s_MotionVectors, current_coord, 0);

    // Compute the reprojected surface point coord
    vec2 surface_point_coord = surface_point_reprojection(current_coord, motion.xy, size);

    // Compute the reprojected hit point coord
    vec2 hit_point_coord = hit_point_reprojection(world_pos, ray_length, size);

    // If the pixel roughness is below the glossy roughness threshold, use the reprojected hit point coord,
    // otherwise you the reprojected surface point coord.
    vec2 reprojected_coord = (roughness < GLOSSY_ROUGHNESS_THRESHOLD && ray_length > 0.0f) ? hit_point_coord : surface_point_coord;

    float history_length;
    vec4  prev_color;
    bool  success  = load_prev_data(current_coord, surface_point_coord, motion, prev_color, history_length);
    history_length = min(32.0f, success ? history_length + 1.0f : 1.0f);

    prev_color.xyz = tonemap(prev_color.xyz);

    // Clamp
    if (success)
    {
        float std_dev_scale = roughness < GLOSSY_ROUGHNESS_THRESHOLD ? 1.0f : 10.0f;
        vec3  color_std_dev = neighborhood_standard_deviation(current_coord) * std_dev_scale;

        vec3 radiance_min = color - color_std_dev;
        vec3 radiance_max = color + color_std_dev;

        prev_color.xyz = clip_aabb(radiance_min, radiance_max, prev_color.xyz);
    }

    // this adjusts the alpha for the case where insufficient history is available.
    // It boosts the temporal accumulation to give the samples equal weights in
    // the beginning.
    const float alpha = success ? max(u_PushConstants.alpha, 1.0 / history_length) : 1.0;

    vec4 out_color = mix(prev_color, vec4(color, 0.0f), alpha);

    out_color.xyz = tonemap_invert(out_color.xyz);

    // temporal integration
    imageStore(i_Color, current_coord, out_color);
    imageStore(i_HistoryLength, current_coord, vec4(history_length));
}

// ------------------------------------------------------------------